<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>SVM用于分类任务</title>
    <link href="/2023/05/08/SVM%E7%94%A8%E4%BA%8E%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/"/>
    <url>/2023/05/08/SVM%E7%94%A8%E4%BA%8E%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="自实现核SVM用于分类任务"><a href="#自实现核SVM用于分类任务" class="headerlink" title="自实现核SVM用于分类任务"></a>自实现核SVM用于分类任务</h1><p>支持向量机是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。给定一组训练实例，每个训练实例被标记为属于两个类别中的一个或另一个，SVM训练算法创建一个将新的实例分配给两个类别之一的模型，使其成为非概率二元线性分类器。SVM模型是将实例表示为空间中的点，这样映射就使得单独类别的实例被尽可能宽的明显的间隔分开。然后，将新的实例映射到同一空间，并基于它们落在间隔的哪一侧来预测所属类别。</p><p>在这里，考虑基于核方法的支持向量机，并使用SMO算法去训练它，这是LIBSVM和sklearn中训练核SVM的方法，但在project1中我自行实现SMO算法求解器。</p><h2 id="求解SVM对偶问题"><a href="#求解SVM对偶问题" class="headerlink" title="求解SVM对偶问题"></a>求解SVM对偶问题</h2><p>考虑二分类核SVM，给定训练数据${({x}<em>i, y_i)}</em>{i=1}^n$，其中$n$是样本数，$ x_{i}\in R^d$，$y\in{-1, +1}$，核SVM的对偶问题尝试优化${\alpha}$：</p><p>$$<br>\min_{ \alpha}\quad\frac12 \alpha^TQ\alpha+ e^T{\alpha}\<br>\text{s.t.}\quad0\leq\alpha_i\leq C,i=1,\cdots,n<br>$$</p><p>其中$Q$为核矩阵：</p><p>$$<br>Q_{ij}=k({x}_i,{x}_j)<br>$$</p><h2 id="SMO算法"><a href="#SMO算法" class="headerlink" title="SMO算法"></a>SMO算法</h2><p>SMO（Sequential Minimal Optimization）是求解SVM问题的高效算法之一，libSVM采用的正是该算法。SMO算法其实是一种启发式算法：先选择两个变量 $α_i$ 和 $α_j$ ，然后固定其他参数，从而将问题转化成一个二变量的二次规划问题。求出能使目标最大的一对 $α_i$ 和$α_j$ 后，将它们固定，再选择两个变量，直到目标值收敛。在选定$i$和$j$后，$\alpha_i$和$\alpha_j$满足下面的更新公式：</p><p>$$<br>\begin{cases}<br>\alpha_i^\text{new}=\dfrac{y_i}{\eta}(E_j-E_i)+\alpha_i^\text{old}\<br>\alpha_j^\text{new}=\dfrac{y_j}{\eta}(E_i-E_j)+\alpha_j^\text{old}<br>\end{cases}<br>$$</p><p>其中$\eta=Q_{11}-2Q_{12}+Q_{22}$，$E_i=f(x_i)-y_i$。但这里并没有考虑$\alpha_i$的约束边界，也就是$[0,C]$。同时也可以发现如何选择$i$和$j$会影响学习效率。</p><p>采用Chang, Chih-Chung, and Chih-Jen Lin. “LIBSVM: a library for support vector machines.” ACM transactions on intelligent systems and technology (TIST) 2.3 (2011): 1-27.中的实现方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> lru_cache<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solver</span>:<br>    <span class="hljs-string">r&#x27;&#x27;&#x27;SMO算法求解器，迭代求解下面的问题:</span><br><span class="hljs-string">    .. math:: \min_&#123;\pmb\alpha&#125;\quad&amp;\frac12\pmb\alpha^T\pmb Q\pmb\alpha+\pmb p^T\pmb\alpha\\</span><br><span class="hljs-string">        \text&#123;s.t.&#125;\quad&amp;\pmb y^T\pmb\alpha=0\\</span><br><span class="hljs-string">        &amp;0\leq\alpha_i\leq C,i=1,\cdots,l</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    Parameters</span><br><span class="hljs-string">    ----------</span><br><span class="hljs-string">    Q : numpy.ndarray</span><br><span class="hljs-string">        优化问题中的 :math:`\pmb Q` 矩阵；</span><br><span class="hljs-string">    p : numpy.ndarray</span><br><span class="hljs-string">        优化问题中的 :math:`\pmb p` 向量；</span><br><span class="hljs-string">    y : numpy.ndarray</span><br><span class="hljs-string">        优化问题中的 :math:`\pmb y` 向量；</span><br><span class="hljs-string">    C : float</span><br><span class="hljs-string">        优化问题中的 :math:`C` 变量；</span><br><span class="hljs-string">    tol : float, default=1e-5</span><br><span class="hljs-string">        变量选择的tolerance，默认为1e-5.</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 Q: np.ndarray,</span><br><span class="hljs-params">                 p: np.ndarray,</span><br><span class="hljs-params">                 y: np.ndarray,</span><br><span class="hljs-params">                 C: <span class="hljs-built_in">float</span>,</span><br><span class="hljs-params">                 tol: <span class="hljs-built_in">float</span> = <span class="hljs-number">1e-5</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>        problem_size = p.shape[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">assert</span> problem_size == y.shape[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">if</span> Q <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">assert</span> problem_size == Q.shape[<span class="hljs-number">0</span>]<br>            <span class="hljs-keyword">assert</span> problem_size == Q.shape[<span class="hljs-number">1</span>]<br><br>        self.Q = Q<br>        self.p = p<br>        self.y = y<br>        self.C = C<br>        self.tol = tol<br>        self.alpha = np.zeros(problem_size)<br><br>        <span class="hljs-comment"># Calculate -y·▽f(α)</span><br>        self.neg_y_grad = -y * p<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">working_set_select</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">r&#x27;&#x27;&#x27;工作集选择，这里采用一阶选择:</span><br><span class="hljs-string">        .. math:: \pmb&#123;I&#125;_&#123;up&#125;(\pmb\alpha)&amp;=\&#123;t|\alpha_t&lt;C,y_t=1\text&#123; or &#125;\alpha_t&gt;0,y_t=-1\&#125;\\</span><br><span class="hljs-string">                 \pmb&#123;I&#125;_&#123;low&#125;(\pmb\alpha)&amp;=\&#123;t|\alpha_t&lt;C,y_t=-1\text&#123; or &#125;\alpha_t&gt;0,y_t=1\&#125;\\</span><br><span class="hljs-string">                 i&amp;\in\arg\max_&#123;t&#125;\&#123;-y_t\nabla_tf(\pmb\alpha)|t\in\pmb&#123;I&#125;_&#123;up&#125;(\pmb\alpha)\&#125;\\</span><br><span class="hljs-string">                 j&amp;\in\arg\max_&#123;t&#125;\&#123;-y_t\nabla_tf(\pmb\alpha)|t\in\pmb&#123;I&#125;_&#123;low&#125;(\pmb\alpha)\&#125;\\</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        Iup = np.argwhere(<br>            np.logical_or(<br>                np.logical_and(self.alpha &lt; self.C, self.y &gt; <span class="hljs-number">0</span>),<br>                np.logical_and(self.alpha &gt; <span class="hljs-number">0</span>, self.y &lt; <span class="hljs-number">0</span>),<br>            )).flatten()<br>        Ilow = np.argwhere(<br>            np.logical_or(<br>                np.logical_and(self.alpha &lt; self.C, self.y &lt; <span class="hljs-number">0</span>),<br>                np.logical_and(self.alpha &gt; <span class="hljs-number">0</span>, self.y &gt; <span class="hljs-number">0</span>),<br>            )).flatten()<br><br>        find_fail = <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">try</span>:<br>            i = Iup[np.argmax(self.neg_y_grad[Iup])]<br>            j = Ilow[np.argmin(self.neg_y_grad[Ilow])]<br>        <span class="hljs-keyword">except</span>:<br>            find_fail = <span class="hljs-literal">True</span><br><br>        <span class="hljs-keyword">if</span> find_fail <span class="hljs-keyword">or</span> self.neg_y_grad[i] - self.neg_y_grad[j] &lt; self.tol:<br>            <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> i, j<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, i: <span class="hljs-built_in">int</span>, j: <span class="hljs-built_in">int</span>, func=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;变量更新，在保证变量满足约束的条件下对两变量进行更新&#x27;&#x27;&#x27;</span><br>        Qi, Qj = self.get_Q(i, func), self.get_Q(j, func)<br>        yi, yj = self.y[i], self.y[j]<br>        alpha_i, alpha_j = self.alpha[i], self.alpha[j]<br><br>        quad_coef = Qi[i] + Qj[j] - <span class="hljs-number">2</span> * yi * yj * Qi[j]<br>        <span class="hljs-keyword">if</span> quad_coef &lt;= <span class="hljs-number">0</span>:<br>            quad_coef = <span class="hljs-number">1e-12</span><br><br>        <span class="hljs-keyword">if</span> yi * yj == -<span class="hljs-number">1</span>:<br>            delta = (self.neg_y_grad[i] * yi +<br>                     self.neg_y_grad[j] * yj) / quad_coef<br>            diff = alpha_i - alpha_j<br>            self.alpha[i] += delta<br>            self.alpha[j] += delta<br><br>            <span class="hljs-keyword">if</span> diff &gt; <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">if</span> (self.alpha[j] &lt; <span class="hljs-number">0</span>):<br>                    self.alpha[j] = <span class="hljs-number">0</span><br>                    self.alpha[i] = diff<br><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">if</span> (self.alpha[i] &lt; <span class="hljs-number">0</span>):<br>                    self.alpha[i] = <span class="hljs-number">0</span><br>                    self.alpha[j] = -diff<br><br>            <span class="hljs-keyword">if</span> diff &gt; <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">if</span> (self.alpha[i] &gt; self.C):<br>                    self.alpha[i] = self.C<br>                    self.alpha[j] = self.C - diff<br><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">if</span> (self.alpha[j] &gt; self.C):<br>                    self.alpha[j] = self.C<br>                    self.alpha[i] = self.C + diff<br><br>        <span class="hljs-keyword">else</span>:<br>            delta = (self.neg_y_grad[j] * yj -<br>                     self.neg_y_grad[i] * yi) / quad_coef<br>            <span class="hljs-built_in">sum</span> = self.alpha[i] + self.alpha[j]<br>            self.alpha[i] -= delta<br>            self.alpha[j] += delta<br><br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">sum</span> &gt; self.C:<br>                <span class="hljs-keyword">if</span> self.alpha[i] &gt; self.C:<br>                    self.alpha[i] = self.C<br>                    self.alpha[j] = <span class="hljs-built_in">sum</span> - self.C<br><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">if</span> self.alpha[j] &lt; <span class="hljs-number">0</span>:<br>                    self.alpha[j] = <span class="hljs-number">0</span><br>                    self.alpha[i] = <span class="hljs-built_in">sum</span><br><br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">sum</span> &gt; self.C:<br>                <span class="hljs-keyword">if</span> self.alpha[j] &gt; self.C:<br>                    self.alpha[j] = self.C<br>                    self.alpha[i] = <span class="hljs-built_in">sum</span> - self.C<br><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">if</span> self.alpha[i] &lt; <span class="hljs-number">0</span>:<br>                    self.alpha[i] = <span class="hljs-number">0</span><br>                    self.alpha[j] = <span class="hljs-built_in">sum</span><br><br>        delta_i = self.alpha[i] - alpha_i<br>        delta_j = self.alpha[j] - alpha_j<br>        self.neg_y_grad -= self.y * (delta_i * Qi + delta_j * Qj)<br>        <span class="hljs-keyword">return</span> delta_i, delta_j<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_rho</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">float</span>:<br>        <span class="hljs-string">r&#x27;&#x27;&#x27;计算偏置项</span><br><span class="hljs-string">        </span><br><span class="hljs-string">        .. math:: \rho=\dfrac&#123;\sum_&#123;i:0&lt;\alpha_i&lt;C&#125;y_i\nabla_if(\pmb\alpha)&#125;&#123;|\&#123;i\vert0&lt;\alpha_i&lt;C\&#125;|&#125;</span><br><span class="hljs-string">        如果不存在满足条件的支持向量，那么</span><br><span class="hljs-string">        .. math:: -M(\pmb\alpha)&amp;=\max\&#123;y_i\nabla_if(\pmb\alpha)|\alpha_i=0,y_i=-1\text&#123; or &#125;\alpha_i=C,y_i=1\&#125;\\</span><br><span class="hljs-string">                  -m(\pmb\alpha)&amp;=\max\&#123;y_i\nabla_if(\pmb\alpha)|\alpha_i=0,y_i=1\text&#123; or &#125;\alpha_i=C,y_i=-1\&#125;\\</span><br><span class="hljs-string">                  \rho&amp;=-\dfrac&#123;M(\pmb\alpha)+m(\pmb\alpha)&#125;&#123;2&#125;</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        sv = np.logical_and(<br>            self.alpha &gt; <span class="hljs-number">0</span>,<br>            self.alpha &lt; self.C,<br>        )<br>        <span class="hljs-keyword">if</span> sv.<span class="hljs-built_in">sum</span>() &gt; <span class="hljs-number">0</span>:<br>            rho = -np.average(self.neg_y_grad[sv])<br>        <span class="hljs-keyword">else</span>:<br>            ub_id = np.logical_or(<br>                np.logical_and(self.alpha == <span class="hljs-number">0</span>, self.y &lt; <span class="hljs-number">0</span>),<br>                np.logical_and(self.alpha == self.C, self.y &gt; <span class="hljs-number">0</span>),<br>            )<br>            lb_id = np.logical_or(<br>                np.logical_and(self.alpha == <span class="hljs-number">0</span>, self.y &gt; <span class="hljs-number">0</span>),<br>                np.logical_and(self.alpha == self.C, self.y &lt; <span class="hljs-number">0</span>),<br>            )<br>            rho = -(self.neg_y_grad[lb_id].<span class="hljs-built_in">min</span>() +<br>                    self.neg_y_grad[ub_id].<span class="hljs-built_in">max</span>()) / <span class="hljs-number">2</span><br>        <span class="hljs-keyword">return</span> rho<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_Q</span>(<span class="hljs-params">self, i: <span class="hljs-built_in">int</span>, func=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;获取核矩阵的第i行/列，即</span><br><span class="hljs-string">        </span><br><span class="hljs-string">        .. math:: [K(\pmb x_1, \pmb x_i),\cdots,K(\pmb x_l, \pmb x_i)]</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-keyword">return</span> self.Q[i]<br></code></pre></td></tr></table></figure><h2 id="SVM接口的实现"><a href="#SVM接口的实现" class="headerlink" title="SVM接口的实现"></a>SVM接口的实现</h2><p>为了让模型能够进行参数选择等功能，按照sklearn接口的模式编写SVM模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.base <span class="hljs-keyword">import</span> BaseEstimator<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">from</span> solver <span class="hljs-keyword">import</span> Solver, SolverWithCache<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BiLinearSVC</span>(<span class="hljs-title class_ inherited__">BaseEstimator</span>):<br>    <span class="hljs-string">r&#x27;&#x27;&#x27;二分类线性SVM，该类被多分类LinearSVC继承，所以不需要使用它。</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    通过求解对偶问题</span><br><span class="hljs-string">    .. math:: \min_&#123;\pmb\alpha&#125;\quad&amp;\dfrac12\pmb\alpha^\top Q\pmb\alpha-\pmb&#123;e&#125;^\top\pmb&#123;\alpha&#125;\\</span><br><span class="hljs-string">        \text&#123;s.t.&#125;\quad&amp; \pmb&#123;y&#125;^\top\pmb\alpha=0,\\</span><br><span class="hljs-string">        &amp;0\leqslant\alpha_i\leqslant C,i=1,\cdots ,l</span><br><span class="hljs-string">    得到决策边界</span><br><span class="hljs-string">    .. math:: f(\pmb x)=\sum_&#123;i=1&#125;^ly_i\alpha_i\pmb x_i^T\pmb x-\rho</span><br><span class="hljs-string">    Parameters</span><br><span class="hljs-string">    ----------</span><br><span class="hljs-string">    C : float, default=1</span><br><span class="hljs-string">        SVM的正则化参数，默认为1；</span><br><span class="hljs-string">    max_iter : int, default=1000</span><br><span class="hljs-string">        SMO算法迭代次数，默认1000；</span><br><span class="hljs-string">    tol : float, default=1e-5</span><br><span class="hljs-string">        SMO算法的容忍度参数，默认1e-5；</span><br><span class="hljs-string">    cache_size : int, default=256</span><br><span class="hljs-string">        lru缓存大小，默认256，如果为0则不使用缓存，计算Q矩阵然后求解.</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 C: <span class="hljs-built_in">float</span> = <span class="hljs-number">1.</span>,</span><br><span class="hljs-params">                 max_iter: <span class="hljs-built_in">int</span> = <span class="hljs-number">1000</span>,</span><br><span class="hljs-params">                 tol: <span class="hljs-built_in">float</span> = <span class="hljs-number">1e-5</span>,</span><br><span class="hljs-params">                 cache_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">256</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.C = C<br>        self.max_iter = max_iter<br>        self.tol = tol<br>        self.cache_size = cache_size<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, X: np.ndarray, y: np.ndarray</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;训练模型</span><br><span class="hljs-string">        Parameters</span><br><span class="hljs-string">        ----------</span><br><span class="hljs-string">        X : np.ndarray</span><br><span class="hljs-string">            训练集特征;</span><br><span class="hljs-string">        y : np.array</span><br><span class="hljs-string">            训练集标签，建议0为负标签，1为正标签.</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        X, y = np.array(X), np.array(y, dtype=<span class="hljs-built_in">float</span>)<br>        y[y != <span class="hljs-number">1</span>] = -<span class="hljs-number">1</span><br>        l, self.n_features = X.shape<br>        p = -np.ones(l)<br><br>        w = np.zeros(self.n_features)<br>        <span class="hljs-keyword">if</span> self.cache_size == <span class="hljs-number">0</span>:<br>            Q = y.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>) * y * np.matmul(X, X.T)<br>            solver = Solver(Q, p, y, self.C, self.tol)<br>        <span class="hljs-keyword">else</span>:<br>            solver = SolverWithCache(p, y, self.C, self.tol, self.cache_size)<br><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">func</span>(<span class="hljs-params">i</span>):<br>            <span class="hljs-keyword">return</span> y * np.matmul(X, X[i]) * y[i]<br><br>        <span class="hljs-keyword">for</span> n_iter <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.max_iter):<br>            i, j = solver.working_set_select()<br>            <span class="hljs-keyword">if</span> i &lt; <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">break</span><br><br>            delta_i, delta_j = solver.update(i, j, func)<br>            w += delta_i * y[i] * X[i] + delta_j * y[j] * X[j]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;LinearSVC not coverage with &#123;&#125; iterations&quot;</span>.<span class="hljs-built_in">format</span>(<br>                self.max_iter))<br><br>        self.coef_ = (w, solver.calculate_rho())<br>        <span class="hljs-keyword">return</span> self<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decision_function</span>(<span class="hljs-params">self, X: np.ndarray</span>) -&gt; np.ndarray:<br>        <span class="hljs-string">&#x27;&#x27;&#x27;决策函数，输出预测值&#x27;&#x27;&#x27;</span><br>        <span class="hljs-keyword">return</span> np.matmul(self.coef_[<span class="hljs-number">0</span>], np.array(X).T) - self.coef_[-<span class="hljs-number">1</span>]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, X: np.ndarray</span>) -&gt; np.ndarray:<br>        <span class="hljs-string">&#x27;&#x27;&#x27;预测函数，输出预测标签(0-1)&#x27;&#x27;&#x27;</span><br>        <span class="hljs-keyword">return</span> (self.decision_function(np.array(X)) &gt;= <span class="hljs-number">0</span>).astype(<span class="hljs-built_in">int</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">score</span>(<span class="hljs-params">self, X: np.ndarray, y: np.ndarray</span>) -&gt; <span class="hljs-built_in">float</span>:<br>        <span class="hljs-string">&#x27;&#x27;&#x27;评估函数，给定特征和标签，输出正确率&#x27;&#x27;&#x27;</span><br>        <span class="hljs-keyword">return</span> accuracy_score(y, self.predict(X))<br></code></pre></td></tr></table></figure><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>选用UCI数据集中的<a href="http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/">威斯康辛乳腺癌数据</a>作为实验数据集，首先查看数据分布等信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelEncoder<br><br><br><span class="hljs-comment"># 读取数据集</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_wdbc</span>():<br>    feature_list, target_list = [], []<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;data/wdbc.data&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        lines = f.readlines()<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tqdm(lines, desc=<span class="hljs-string">&#x27;reading data&#x27;</span>):<br>        line_split = line.split(<span class="hljs-string">&#x27;,&#x27;</span>)[<span class="hljs-number">1</span>:]<br>        feature_list.append(line_split[<span class="hljs-number">1</span>:])<br>        target_list.append(line_split[<span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">return</span> (<br>        np.array(feature_list).astype(<span class="hljs-built_in">float</span>),<br>        LabelEncoder().fit_transform(np.array(target_list)),<br>    )<br><br><br>X, y = read_wdbc()<br><span class="hljs-built_in">print</span>(X.shape, y.shape)<br></code></pre></td></tr></table></figure><pre><code class="hljs">reading data: 100%|██████████████████████████████████████████████████████████████████████████| 569/569 [00:00&lt;?, ?it/s](569, 30) (569,)</code></pre><p>随机选10个特征观察相关性，注意到一些特征间存在很强的线性相关性，此外，很多特征的分布是近似正态分布，比较适合SVM模型分类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>sns.pairplot(pd.DataFrame(X[:, np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">30</span>, <span class="hljs-number">10</span>)]))<br></code></pre></td></tr></table></figure><pre><code class="hljs">&lt;seaborn.axisgrid.PairGrid at 0x1a6c91c4d90&gt;</code></pre><img src="/2023/05/08/SVM%E7%94%A8%E4%BA%8E%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/output_8_1.png" class="" title="图片引用方法一"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler, StandardScaler<br><span class="hljs-keyword">from</span> svm <span class="hljs-keyword">import</span> BiLinearSVC, BiKernelSVC<br><br><span class="hljs-comment"># 训练集测试集划分</span><br>train_X, test_X, train_y, test_y = train_test_split(<br>    X,<br>    y,<br>    train_size=<span class="hljs-number">0.8</span>,<br>    random_state=<span class="hljs-number">42</span>,<br>)<br><br><span class="hljs-comment"># 数据归一化</span><br>stder = MinMaxScaler().fit(train_X)<br>train_X = stder.transform(train_X)<br>test_X = stder.transform(test_X)<br><br><span class="hljs-comment"># 线性核SVM和RBF核SVM</span><br>linear_model = BiLinearSVC().fit(train_X, train_y)<br>rbf_model = BiKernelSVC().fit(train_X, train_y)<br>acc1 = linear_model.score(test_X, test_y)<br>acc2 = rbf_model.score(test_X, test_y)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;LinearSVM : &#123;:2.4f&#125;%, Kernel SVM : &#123;:2.4f&#125;%&quot;</span>.<span class="hljs-built_in">format</span>(<br>    acc1 * <span class="hljs-number">100</span>, acc2 * <span class="hljs-number">100</span>))<br><br></code></pre></td></tr></table></figure><pre><code class="hljs">LinearSVM : 98.2456%, Kernel SVM : 96.4912%</code></pre><p>在Project1中，似乎线性分类器比核RBF效果更好。</p><h2 id="参数选择"><a href="#参数选择" class="headerlink" title="参数选择"></a>参数选择</h2><p>线性SVM只有一个超参数$C$，观察不同$C$情况下模型的表现，同时选出最优参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> warnings <span class="hljs-keyword">import</span> filterwarnings<br><br>filterwarnings(<span class="hljs-string">&#x27;ignore&#x27;</span>)<br>C_list = np.logspace(-<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">50</span>)<br>n_iter = <span class="hljs-number">20</span><br>score_matrix = np.zeros((<span class="hljs-built_in">len</span>(C_list), n_iter))<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(n_iter)):<br>    train_X, test_X, train_y, test_y = train_test_split(<br>        X,<br>        y,<br>        train_size=<span class="hljs-number">0.8</span>,<br>    )<br>    stder = MinMaxScaler().fit(train_X)<br>    train_X = stder.transform(train_X)<br>    test_X = stder.transform(test_X)<br>    <span class="hljs-keyword">for</span> j, C <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(C_list):<br>        score_matrix[j, i] = BiLinearSVC(C=C, max_iter=<span class="hljs-number">2500</span>).fit(<br>            train_X,<br>            train_y,<br>        ).score(<br>            test_X,<br>            test_y,<br>        )<br><br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><br>sns.<span class="hljs-built_in">set</span>()<br><br>mean_score = score_matrix.mean(<span class="hljs-number">1</span>)<br>plt.plot(C_list, mean_score, label=<span class="hljs-string">&#x27;Test accuracy&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&quot;C&quot;</span>)<br>plt.show()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;best C : &#123;&#125;, best accuracy : &#123;:2.4f&#125;%&quot;</span>.<span class="hljs-built_in">format</span>(<br>    C_list[mean_score.argmax()],<br>    mean_score.<span class="hljs-built_in">max</span>() * <span class="hljs-number">100</span>,<br>))<br></code></pre></td></tr></table></figure><pre><code class="hljs">100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:46&lt;00:00,  2.32s/it]</code></pre><img src="/2023/05/08/SVM%E7%94%A8%E4%BA%8E%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/output_11_1.png" class=""><pre><code class="hljs">best C : 3.3932217718953264, best accuracy : 97.4123%</code></pre><p>接下来看核SVM的表现，首先用不同的核函数进行实验，发现性能最优的是RBF。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python">kernel_list = [<span class="hljs-string">&quot;rbf&quot;</span>, <span class="hljs-string">&quot;poly&quot;</span>, <span class="hljs-string">&quot;sigmoid&quot;</span>]<br>n_iter = <span class="hljs-number">20</span><br><br>score_matrix = np.zeros((<span class="hljs-built_in">len</span>(kernel_list), n_iter))<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(n_iter)):<br>    train_X, test_X, train_y, test_y = train_test_split(<br>        X,<br>        y,<br>        train_size=<span class="hljs-number">0.8</span>,<br>    )<br>    stder = MinMaxScaler().fit(train_X)<br>    train_X = stder.transform(train_X)<br>    test_X = stder.transform(test_X)<br>    <span class="hljs-keyword">for</span> j, kernel <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(kernel_list):<br>        score_matrix[j, i] = BiKernelSVC(<br>            kernel=kernel,<br>            max_iter=<span class="hljs-number">5000</span>,<br>        ).fit(<br>            train_X,<br>            train_y,<br>        ).score(<br>            test_X,<br>            test_y,<br>        )<br><br><span class="hljs-keyword">for</span> i, kernel <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(kernel_list):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;:7s&#125;, mean : &#123;:4.2f&#125;%, std : &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(<br>        kernel,<br>        score_matrix[i].mean() * <span class="hljs-number">100</span>,<br>        (score_matrix[i] * <span class="hljs-number">100</span>).std(),<br>    ))<br><br></code></pre></td></tr></table></figure><pre><code class="hljs">100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00&lt;00:00, 22.79it/s]rbf    , mean : 96.80%, std : 1.8664844588555454poly   , mean : 94.96%, std : 1.9392711376696599sigmoid, mean : 96.36%, std : 1.2490377952542226</code></pre><p>接下来为RBF选取最优参数$C,\gamma$：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python">C_list = np.logspace(-<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">20</span>)<br>G_list = np.logspace(-<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">20</span>)<br>n_iter = <span class="hljs-number">20</span><br>score_matrix = np.zeros((<span class="hljs-built_in">len</span>(C_list), <span class="hljs-built_in">len</span>(G_list), n_iter))<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(n_iter)):<br>    train_X, test_X, train_y, test_y = train_test_split(<br>        X,<br>        y,<br>        train_size=<span class="hljs-number">0.8</span>,<br>    )<br>    stder = MinMaxScaler().fit(train_X)<br>    train_X = stder.transform(train_X)<br>    test_X = stder.transform(test_X)<br>    <span class="hljs-keyword">for</span> j, C <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(C_list):<br>        <span class="hljs-keyword">for</span> k, gamma <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(G_list):<br>            score_matrix[j, k, i] = BiKernelSVC(<br>                C=C,<br>                gamma=gamma,<br>                max_iter=<span class="hljs-number">2500</span>,<br>            ).fit(<br>                train_X,<br>                train_y,<br>            ).score(<br>                test_X,<br>                test_y,<br>            )<br></code></pre></td></tr></table></figure><pre><code class="hljs">100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [04:21&lt;00:00, 13.06s/it]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">sns.heatmap(<br>    score_matrix.mean(-<span class="hljs-number">1</span>),<br>    cmap=<span class="hljs-string">&#x27;viridis&#x27;</span>,<br>    xticklabels=[<span class="hljs-string">&quot;&#123;:.4f&#125;&quot;</span>.<span class="hljs-built_in">format</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> G_list],<br>    yticklabels=[<span class="hljs-string">&quot;&#123;:.4f&#125;&quot;</span>.<span class="hljs-built_in">format</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> C_list],<br>)<br>plt.xlabel(<span class="hljs-string">r&quot;$\gamma$&quot;</span>)<br>plt.ylabel(<span class="hljs-string">r&quot;$C$&quot;</span>)<br>plt.title(<span class="hljs-string">r&quot;Test accuracy under different $C$ and $\gamma$&quot;</span>)<br>plt.show()<br>argmax = score_matrix.mean(-<span class="hljs-number">1</span>).argmax()<br>argmax_row, argmax_col = argmax // <span class="hljs-built_in">len</span>(G_list), argmax % <span class="hljs-built_in">len</span>(G_list)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Best parameters : C=&#123;:.4f&#125;, γ=&#123;:.4f&#125;, acc=&#123;:.2f&#125;%&quot;</span>.<span class="hljs-built_in">format</span>(<br>    C_list[argmax_row],<br>    G_list[argmax_col],<br>    score_matrix.mean(-<span class="hljs-number">1</span>).flatten()[argmax] * <span class="hljs-number">100</span>,<br>))<br></code></pre></td></tr></table></figure><img src="/2023/05/08/SVM%E7%94%A8%E4%BA%8E%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/output_16_0.png" class=""><pre><code class="hljs">Best parameters : C=6.9519, γ=1.1288, acc=98.11%</code></pre>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于矩阵分解的推荐系统</title>
    <link href="/2023/05/08/%E5%9F%BA%E4%BA%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%9A%84%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    <url>/2023/05/08/%E5%9F%BA%E4%BA%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%9A%84%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h3 id="一-实验目的"><a href="#一-实验目的" class="headerlink" title="一.实验目的"></a>一.实验目的</h3><p>​在信息化和大数据的时代，推荐系统是解决如何精准地挖掘出用户的偏好这一问题的一个研究主题。本次次实践作业关于如何使用矩阵分解技术解决推荐问题。  </p><p>问题定义：给定一个用户评分矩阵 $\mathbf{R}\in\mathbb{R}^{m\times n}$，其中$m$为用户（user）的数量，$n$为物品（item）的数量。矩阵元素$r_{ij}\in\mathbf{R}$表示用户$u_i$为物品$v_j$的评分值。任务目标有两个：</p><ul><li>通过矩阵分解和凸优化技术，获得每个用户$u_i$和物品$v_j$的隐式向量，分别记作$\mathbf{u}_i\in\mathbb{R}^{k}$和$\mathbf{v}_i\in\mathbb{R}^{k}$，其中$k$为向量维度；所有用户和物品分别组成矩阵$\mathbf{P}\in\mathbb{R}^{m\times k}$和$\mathbf{Q}\in\mathbb{R}^{n\times k}$；</li><li>根据获得的用户和物品向量，预测该用户对某个物品的偏好程度$\hat{r}_{ij}=\mathbf{u}_i\mathbf{v}_i^{T}$；</li></ul><p>因为在实际应用中，这个用户评分矩阵式稀疏的。例如某电影网站一共有100k用户和10k部电影，有一些用户可能只看不超过10部电影，或者有些的电影可能被观影的人数很少。换句话说，这个用户评分矩阵存在大量的缺失值，因此通过矩阵分解可以先挖掘出已存在的用户行为，再预测这些缺失值。</p><h3 id="二-数据集"><a href="#二-数据集" class="headerlink" title="二.数据集"></a>二.数据集</h3><p>选取电影评分数据集，包括约20k用户和10k物品。总共有超过240k评分数据。根据评分数据划分了训练集（237k评分数据）、验证集（10k评分数据）和测试集（50k评分数据）。</p><ul><li>其中训练集和验证集中，每一条数据表示为$(u_i, v_j, r_{ij})$三元组；</li><li>测试集则用于评测，其只有用户和商品$(u_i, v_j)$，需要预测出他们的评分；</li><li>验证集和测试集中出现的所有用户和商品确保一定在训练集中存在，即不考虑冷启动问题；</li></ul><h3 id="三-实验任务"><a href="#三-实验任务" class="headerlink" title="三.实验任务"></a>三.实验任务</h3><ol><li><p>实现矩阵分解推荐系统项目，包括数据读取、模型训练、优化算法、模型验证与测试；</p><ul><li>实现随机梯度下降和批量梯度下降算法，完成$\mathbf{P}$和$\mathbf{Q}$矩阵的参数更新；</li><li>进一步优化算法，包括正则化、偏置项和协同过滤；</li><li>使用或自研其他算法技术来进一步提升矩阵分解的泛化性能；</li></ul></li><li><p>完成代码后，将训练好的模型在测试集上进行预测；</p></li><li><p>对矩阵分解在推荐系统的应用背景介绍、个人理解；</p><ul><li>几种优化算法、以及改进算法的代码实现原理，以及对应的实验对比结果；</li><li>探索矩阵分解算法的一些优势和缺点；</li><li>项目完成感悟和总结。</li></ul></li></ol><h3 id="四-实验过程"><a href="#四-实验过程" class="headerlink" title="四.实验过程"></a>四.实验过程</h3><h4 id="主程序"><a href="#主程序" class="headerlink" title="主程序"></a>主程序</h4><p>设置超参数，包括学习率、迭代次数、隐藏层大小、后续算法优化选项等。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import pandas as pd<br>import numpy as np<br><span class="hljs-keyword">from</span> tqdm import tqdm<br>import argparse<br><span class="hljs-keyword">from</span> model import MatrixDecomForRecSys<br><span class="hljs-keyword">from</span> metrics import RMSE<br><br>np.random.seed(42)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    # <span class="hljs-built_in">set</span> hyper-parameter<br>    parser = argparse.ArgumentParser(<span class="hljs-attribute">description</span>=<span class="hljs-string">&quot;Command&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--learning_rate&#x27;</span>, <span class="hljs-attribute">default</span>=0.02, <span class="hljs-attribute">type</span>=float)<br>    parser.add_argument(<span class="hljs-string">&#x27;--batch_size&#x27;</span>, <span class="hljs-attribute">default</span>=8, <span class="hljs-attribute">type</span>=int)<br>    parser.add_argument(<span class="hljs-string">&#x27;--epoch&#x27;</span>, <span class="hljs-attribute">default</span>=10, <span class="hljs-attribute">type</span>=int)<br>    parser.add_argument(<span class="hljs-string">&#x27;--reg_p&#x27;</span>, <span class="hljs-attribute">default</span>=0.01, <span class="hljs-attribute">type</span>=float)<br>    parser.add_argument(<span class="hljs-string">&#x27;--reg_q&#x27;</span>, <span class="hljs-attribute">default</span>=0.01, <span class="hljs-attribute">type</span>=float)<br>    parser.add_argument(<span class="hljs-string">&#x27;--reg_b&#x27;</span>, <span class="hljs-attribute">default</span>=0.01, <span class="hljs-attribute">type</span>=float)<br>    parser.add_argument(<span class="hljs-string">&#x27;--gamma&#x27;</span>, <span class="hljs-attribute">default</span>=0, <span class="hljs-attribute">type</span>=float)<br>    parser.add_argument(<span class="hljs-string">&#x27;--hidden_size&#x27;</span>, <span class="hljs-attribute">default</span>=16, <span class="hljs-attribute">type</span>=int)<br>    parser.add_argument(<span class="hljs-string">&#x27;--bias&#x27;</span>,<br>                        <span class="hljs-attribute">default</span>=<span class="hljs-literal">True</span>,<br>                        <span class="hljs-attribute">action</span>=<span class="hljs-string">&#x27;store_true&#x27;</span>,<br>                        <span class="hljs-attribute">help</span>=<span class="hljs-string">&#x27;add bias&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--optimizer_type&#x27;</span>,<br>                        <span class="hljs-attribute">default</span>=<span class="hljs-string">&quot;SGD&quot;</span>,<br>                        <span class="hljs-attribute">type</span>=str,<br>                        <span class="hljs-attribute">help</span>=<span class="hljs-string">&quot;SGD or BGD&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--train&#x27;</span>,<br>                        <span class="hljs-attribute">default</span>=<span class="hljs-literal">False</span>,<br>                        <span class="hljs-attribute">action</span>=<span class="hljs-string">&#x27;store_true&#x27;</span>,<br>                        <span class="hljs-attribute">help</span>=<span class="hljs-string">&#x27;is train&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--test&#x27;</span>,<br>                        <span class="hljs-attribute">default</span>=<span class="hljs-literal">False</span>,<br>                        <span class="hljs-attribute">action</span>=<span class="hljs-string">&#x27;store_true&#x27;</span>,<br>                        <span class="hljs-attribute">help</span>=<span class="hljs-string">&#x27;is test&#x27;</span>)<br><br>    args = parser.parse_args()<br><br>    # reading training data<br>    dtype = [(<span class="hljs-string">&quot;userId&quot;</span>, np.int32), (<span class="hljs-string">&quot;movieId&quot;</span>, np.int32),<br>             (<span class="hljs-string">&quot;rating&quot;</span>, np.float32)]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Reading training data ...&quot;</span>)<br>    train_dataset = pd.read_csv(<span class="hljs-string">&quot;data/train.csv&quot;</span>,<br>                                <span class="hljs-attribute">usecols</span>=range(3),<br>                                <span class="hljs-attribute">dtype</span>=dict(dtype))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Reading developing data ...&quot;</span>)<br>    dev_dataset = pd.read_csv(<span class="hljs-string">&quot;data/dev.csv&quot;</span>,<br>                              <span class="hljs-attribute">usecols</span>=range(3),<br>                              <span class="hljs-attribute">dtype</span>=dict(dtype))<br><br>    model = MatrixDecomForRecSys(<span class="hljs-attribute">lr</span>=args.learning_rate,<br>                                 <span class="hljs-attribute">batch_size</span>=args.batch_size,<br>                                 <span class="hljs-attribute">reg_p</span>=args.reg_p,<br>                                 <span class="hljs-attribute">reg_q</span>=args.reg_q,<br>                                 <span class="hljs-attribute">reg_b</span>=args.reg_b,<br>                                 <span class="hljs-attribute">gamma</span>=args.gamma,<br>                                 <span class="hljs-attribute">hidden_size</span>=args.hidden_size,<br>                                 <span class="hljs-attribute">bias</span>=args.bias,<br>                                 <span class="hljs-attribute">epoch</span>=args.epoch,<br>                                 columns=[<span class="hljs-string">&quot;userId&quot;</span>, <span class="hljs-string">&quot;movieId&quot;</span>, <span class="hljs-string">&quot;rating&quot;</span>],<br>                                 <span class="hljs-attribute">metric</span>=RMSE)<br>    model.load_dataset(<span class="hljs-attribute">train_data</span>=train_dataset, <span class="hljs-attribute">dev_data</span>=dev_dataset)<br><br>    <span class="hljs-keyword">if</span> args.train:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Starting training ...&quot;</span>)<br>        model.train(<span class="hljs-attribute">optimizer_type</span>=args.optimizer_type)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Finish training.&quot;</span>)<br><br>    <span class="hljs-keyword">if</span> args.test:<br>        dtype = [(<span class="hljs-string">&quot;userId&quot;</span>, np.int32), (<span class="hljs-string">&quot;movieId&quot;</span>, np.int32)]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Reading testing data ...&quot;</span>)<br>        test_dataset = pd.read_csv(<span class="hljs-string">&quot;data/test.csv&quot;</span>,<br>                                   <span class="hljs-attribute">usecols</span>=range(2),<br>                                   <span class="hljs-attribute">dtype</span>=dict(dtype))<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Starting predicting ...&quot;</span>)<br>        model.test(test_dataset)<br>        <span class="hljs-built_in">print</span>(<br>            <span class="hljs-string">&quot;Finish predicting, you can submit your results on the leaderboard.&quot;</span><br>        )<br><br></code></pre></td></tr></table></figure><h4 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_dataset</span>(<span class="hljs-params">self, train_data, dev_data</span>):<br>    self.train_data = pd.DataFrame(train_data)<br>    self.dev_data = pd.DataFrame(dev_data)<br><br>    self.users_ratings = train_data.groupby(self.columns[<span class="hljs-number">0</span>]).agg(<br>        [<span class="hljs-built_in">list</span>])[[self.columns[<span class="hljs-number">1</span>], self.columns[<span class="hljs-number">2</span>]]]<br>    self.items_ratings = train_data.groupby(self.columns[<span class="hljs-number">1</span>]).agg(<br>        [<span class="hljs-built_in">list</span>])[[self.columns[<span class="hljs-number">0</span>], self.columns[<span class="hljs-number">2</span>]]]<br><br>    R = pd.DataFrame(<br>        <span class="hljs-number">0.</span>,<br>        index=self.users_ratings.index,<br>        columns=self.items_ratings.index,<br>    )<br>    <span class="hljs-comment">#添加一个进度提示信息</span><br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> tqdm(self.items_ratings.index, desc=<span class="hljs-string">&#x27;Constructing R&#x27;</span>):<br>        R.loc[self.items_ratings.loc[j, (<span class="hljs-string">&#x27;userId&#x27;</span>, <span class="hljs-string">&#x27;list&#x27;</span>)],<br>              j] = self.items_ratings.loc[j, (<span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;list&#x27;</span>)]<br>    self.R = R.values<br>    self.globalMean = self.train_data[self.columns[<span class="hljs-number">2</span>]].mean()<br><br></code></pre></td></tr></table></figure><h4 id="初始化矩阵"><a href="#初始化矩阵" class="headerlink" title="初始化矩阵"></a>初始化矩阵</h4><p>矩阵P表示用户矩阵，矩阵Q表示物品矩阵，矩阵B表示偏置矩阵，用于后续优化提高模型准确率。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs lua">def _init_matrix(<span class="hljs-built_in">self</span>):<br>    P_ = np.<span class="hljs-built_in">random</span>.rand(<br>        <span class="hljs-built_in">len</span>(<span class="hljs-built_in">self</span>.users_ratings),<br>        <span class="hljs-built_in">self</span>.hidden_size,<br>    )<br>    Q_ = np.<span class="hljs-built_in">random</span>.rand(<br>        <span class="hljs-built_in">len</span>(<span class="hljs-built_in">self</span>.items_ratings),<br>        <span class="hljs-built_in">self</span>.hidden_size,<br>    )<br>    B_ = np.zeros((<br>        <span class="hljs-built_in">len</span>(<span class="hljs-built_in">self</span>.users_ratings),<br>        <span class="hljs-built_in">len</span>(<span class="hljs-built_in">self</span>.items_ratings),<br>    ))<br>    <span class="hljs-keyword">return</span> P_, Q_, B_<br></code></pre></td></tr></table></figure><p>更好矩阵的初始化相当于先验信息，对算法优化有一定帮助，这里用随机矩阵初始化用户矩阵和物品矩阵，用全零矩阵初始化偏置矩阵。</p><h4 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h4><p>初始化user、item矩阵，根据optimizer_type选择随机梯度下降和批量梯度下降，在每一次迭代之后，在验证集上验证，保存当前最优解，更新矩阵P、Q、B，判断标准是更低的RMSE。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self, optimizer_type: <span class="hljs-built_in">str</span></span>):<br>    P_, Q_, B_ = self._init_matrix()<br>    <span class="hljs-comment"># 初始化user、item矩阵</span><br>    best_metric_result = <span class="hljs-literal">None</span><br>    best_P, best_Q, best_B = (<br>        <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(self.users_ratings.index, P_)),<br>        <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(self.items_ratings.index, Q_)),<br>        pd.DataFrame(<br>            B_,<br>            index=self.users_ratings.index,<br>            columns=self.items_ratings.index,<br>        ),<br>    )<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.epoch):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Epoch: %d&quot;</span> % i)<br>        <span class="hljs-comment"># 当前epoch，执行优化算法：</span><br>        <span class="hljs-keyword">if</span> optimizer_type == <span class="hljs-string">&quot;SGD&quot;</span>:  <span class="hljs-comment"># 随机梯度下降</span><br>            P_, Q_, B_ = self.sgd(P_, Q_, B_)<br>        <span class="hljs-keyword">elif</span> optimizer_type == <span class="hljs-string">&quot;BGD&quot;</span>:  <span class="hljs-comment"># 批量梯度下降</span><br>            P_, Q_, B_ = self.bgd(P_, Q_, B_, batch_size=self.batch_size)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> NotImplementedError(<span class="hljs-string">&quot;Please choose one of SGD and BGD.&quot;</span>)<br><br>        <span class="hljs-comment"># 当前epoch优化后，在验证集上验证，并保存目前的最优解</span><br>        P = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(self.users_ratings.index, P_))<br>        Q = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(self.items_ratings.index, Q_))<br>        B = pd.DataFrame(<br>            B_,<br>            index=self.users_ratings.index,<br>            columns=self.items_ratings.index,<br>        )<br>        metric_result = self.<span class="hljs-built_in">eval</span>(P, Q, B)<br>        <span class="hljs-comment"># 如果当前的RMSE更低，则保存</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Current dev metric result: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(metric_result))<br>        <span class="hljs-keyword">if</span> best_metric_result <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> metric_result &lt;= best_metric_result:<br>            best_metric_result = metric_result<br>            best_P, best_Q, best_B = P, Q, B<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Best dev metric result: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(best_metric_result))<br><br>    <span class="hljs-comment"># 最后保存最好的P、Q、B</span><br>    np.savez(<span class="hljs-string">&quot;best_pq.npz&quot;</span>, P=best_P, Q=best_Q, B=best_B)<br></code></pre></td></tr></table></figure><h4 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h4><p>实现批量梯度下降SGD，进一步优化包括：考虑偏置项，考虑正则化，考虑协同过滤。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sgd</span>(<span class="hljs-params">self, P_, Q_, B_</span>):<br>    residual = P_ @ Q_.T + B_ - self.R<br>    grad_p = residual @ Q_<br>    grad_q = residual.T @ P_<br><br>    <span class="hljs-comment"># 偏置项</span><br>    grad_b = residual<br><br>    <span class="hljs-comment"># 正则化</span><br>    grad_p += self.reg_p * P_<br>    grad_q += self.reg_q * Q_<br>    grad_b += self.reg_b * B_<br><br>    <span class="hljs-comment"># 协同过滤</span><br>    <span class="hljs-keyword">if</span> self.gamma &gt; <span class="hljs-number">0.</span>:<br>        G = P_ @ P_.T<br>        Gii = np.diagonal(G)<br>        D = np.c_[Gii] + Gii - G<br>        G_div_D2 = np.square(G / D)<br>        grad_filter = np.c_[G_div_D2.<span class="hljs-built_in">sum</span>(<br>            <span class="hljs-number">1</span>) - <span class="hljs-number">2</span> / np.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span> / D, <span class="hljs-number">1</span>)] * P_ - G_div_D2 @ P_ + P_.<span class="hljs-built_in">sum</span>(<span class="hljs-number">0</span>)<br>        grad_p += self.gamma * grad_filter<br><br>    P_ -= self.lr * grad_p<br>    Q_ -= self.lr * grad_q<br>    <span class="hljs-keyword">if</span> self.bias:<br>        B_ -= self.lr * grad_b<br><br>    <span class="hljs-keyword">return</span> P_, Q_, B_<br></code></pre></td></tr></table></figure><p>实现随机梯度下降BGD，进一步优化包括：考虑偏置项，考虑正则化，考虑协同过滤。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">bgd</span>(<span class="hljs-params">self, P_, Q_, B_, batch_size: <span class="hljs-built_in">int</span> </span>):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, P_.shape[<span class="hljs-number">0</span>], batch_size), desc=<span class="hljs-string">&quot;BGD&quot;</span>):<br>        batch_P = P_[i:i + batch_size]<br>        batch_B = B_[i:i + batch_size]<br>        batch_R = self.R[i:i + batch_size]<br>        residual = batch_P @ Q_.T + batch_B - batch_R<br><br>        grad_p = residual @ Q_<br>        grad_q = residual.T @ batch_P<br>        grad_b = residual<br><br>        grad_p += self.reg_p * batch_P<br>        grad_q += self.reg_q * Q_<br>        grad_b += self.reg_b * batch_B<br>        <span class="hljs-comment"># 协同过滤</span><br>        <span class="hljs-keyword">if</span> self.gamma &gt; <span class="hljs-number">0.</span>:<br>            G = batch_P @ batch_P.T<br>            Gii = np.diagonal(G)<br>            D = np.c_[Gii] + Gii - G<br>            G_div_D2 = np.square(G / D)<br>            grad_filter = np.c_[G_div_D2.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>) - <span class="hljs-number">2</span> / np.<span class="hljs-built_in">sum</span>(<br>                <span class="hljs-number">1</span> / D, <span class="hljs-number">1</span>)] * batch_P - G_div_D2 @ batch_P + batch_P.<span class="hljs-built_in">sum</span>(<span class="hljs-number">0</span>)<br>            grad_p += self.gamma * grad_filter<br><br>        P_[i:i + batch_size] -= self.lr * grad_p<br>        Q_ -= self.lr * grad_q<br>        <span class="hljs-keyword">if</span> self.bias:<br>            B_[i:i + batch_size] -= self.lr * grad_b<br>    <span class="hljs-keyword">return</span> P_, Q_, B_<br></code></pre></td></tr></table></figure><h4 id="模型验证与预测"><a href="#模型验证与预测" class="headerlink" title="模型验证与预测"></a>模型验证与预测</h4><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs css">def predict_user_item_rating(self, uid, iid, <span class="hljs-selector-tag">P</span>, <span class="hljs-selector-tag">Q</span>, <span class="hljs-selector-tag">B</span>):<br>    # 如果uid或iid不在，我们使用全剧平均分作为预测结果返回<br>    if uid not in self.users_ratings.index or iid not in self.items_ratings.index:<br>        return self.globalMean<br><br>    p_u = P[uid]<br>    q_i = Q[iid]<br><br>    return np.<span class="hljs-built_in">dot</span>(p_u, q_i) + B.loc[uid, iid]<br><br>def <span class="hljs-built_in">eval</span>(self, P, Q, B):<br>    # 根据当前的P和Q，在dev上进行验证，挑选最好的P和Q向量<br>    dev_loss = <span class="hljs-number">0</span>.<br>    prediction, ground_truth = <span class="hljs-built_in">list</span>(), <span class="hljs-built_in">list</span>()<br>    for uid, iid, real_rating in self.dev_data.<span class="hljs-built_in">itertuples</span>(index=False):<br>        prediction_rating = self.<span class="hljs-built_in">predict_user_item_rating</span>(<br>            uid, iid, P, Q, B)<br>        # dev_loss += <span class="hljs-built_in">abs</span>(prediction_rating - real_rating)<br>        prediction.<span class="hljs-built_in">append</span>(prediction_rating)<br>        ground_truth.<span class="hljs-built_in">append</span>(real_rating)<br><br>    metric_result = self.<span class="hljs-built_in">metric</span>(ground_truth, prediction)<br><br>    return metric_result<br><br>def <span class="hljs-built_in">test</span>(self, test_data):<br>    test_data = pd.<span class="hljs-built_in">DataFrame</span>(test_data)<br>    # 加载训练好的P和Q<br>    best_pq = np.<span class="hljs-built_in">load</span>(<span class="hljs-string">&quot;best_pq.npz&quot;</span>, allow_pickle=True)<br>    P, Q, B = best_pq[<span class="hljs-string">&quot;P&quot;</span>][()], best_pq[<span class="hljs-string">&quot;Q&quot;</span>][()], best_pq[<span class="hljs-string">&quot;B&quot;</span>][()]<br><br>    B = pd.<span class="hljs-built_in">DataFrame</span>(B,index=self.users_ratings.index,columns=self.items_ratings.index,)<br><br>    save_results = <span class="hljs-built_in">list</span>()<br>    for uid, iid in test_data.<span class="hljs-built_in">itertuples</span>(index=False):<br>        pred_rating = self.<span class="hljs-built_in">predict_user_item_rating</span>(uid, iid, P, Q, B)<br>        save_results.<span class="hljs-built_in">append</span>(pred_rating)<br><br>    log_path = <span class="hljs-string">&quot;submit_results.csv&quot;</span><br>    if os.path.<span class="hljs-built_in">exists</span>(log_path):<br>        os.<span class="hljs-built_in">remove</span>(log_path)<br>    file = <span class="hljs-built_in">open</span>(log_path, <span class="hljs-string">&#x27;a+&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>, newline=<span class="hljs-string">&#x27;&#x27;</span>)<br>    csv_writer = csv.<span class="hljs-built_in">writer</span>(file)<br>    csv_writer.<span class="hljs-built_in">writerow</span>([f<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>])<br>    for ei, rating in <span class="hljs-built_in">enumerate</span>(save_results):<br>        csv_writer.<span class="hljs-built_in">writerow</span>([ei, rating])<br>    file.<span class="hljs-built_in">close</span>()<br></code></pre></td></tr></table></figure><h4 id="代码原理"><a href="#代码原理" class="headerlink" title="代码原理"></a>代码原理</h4><p>随机梯度下降（SGD）和批量梯度下降（BGD）这两种算法都是用来更新模型参数，以最小化损失函数。</p><p>在SGD中，模型参数的更新一次只使用一个训练实例。这意味着，在算法的每一次迭代中，模型参数的更新是基于损失函数相对于模型参数的梯度，只使用一个训练实例。由于SGD每次只使用一个训练实例，它比BGD快得多，计算效率也高得多。然而，SGD对模型参数的更新可能是有噪声的，这可能使优化过程不太稳定。</p><p>相反，在BGD中，模型参数的更新是使用损失函数相对于模型参数的平均梯度，使用数据集中的所有训练实例。由于BGD在每次迭代时都使用所有的训练实例，所以它比SGD更慢，计算成本更高。然而，与SGD相比，用BGD对模型参数进行的更新通常噪音较小，而且更稳定。</p><p>在无优化的情况下，令 $\mathbf{e}<em>{ui}^{2} = (\mathbf{r}</em>{ui}-\mathbf{\hat{r}}<em>{ui})^2 = (\mathbf{r}</em>{ui}-\sum_{j=1}^{K}{p_{uj}q_{ji}})^2$ ，则最小化问题简写为<br>$$<br>\min_{P*,Q*}J(R;P,Q)=\frac{1}{2}\sum_{(u,i)\in K}{e_{ui}^2}<br>$$<br>则在第 $t+1$ 次迭代中，参数 $p_{uj}$ 和 $q_{ji}$ 的更新公式为：<br>$$<br>p_{uj}^{(t+1)} \leftarrow p_{uj}^{(t)} + \epsilon \space \sum_{i:(u,i)\in K}{e_{ui}^{(t)}q_{ji}^{t}}<br>\<br>q_{ji}^{(t+1)} \leftarrow q_{ji}^{(t)} + \epsilon \space \sum_{u:(u,i)\in K}{e_{ui}^{(t)}p_{uj}^{t}}<br>$$<br>其中 $e_{ui}^{(t)}=r_{ui}-\sum_{j=1}^{K}{p_{uj}^{(t)}q_{ji}^{(t)}}$ 。</p><p>正则化优化能够相当于给待估计参数一些先验信息，从而缩减模型空间的大小，提升机器学习算法的泛化能力。</p><p>在正则化的情况下，令 $\mathbf{e}<em>{ui}^{2} = (\mathbf{r}</em>{ui}-\mathbf{\hat{r}}<em>{ui})^2 = (\mathbf{r}</em>{ui}-\sum_{j=1}^{K}{p_{uj}q_{ji}})^2$ ，则最小化问题简写为：<br>$$<br>\min_{P*,Q*}J(R;P,Q)=\frac{1}{2}[\space \sum_{(u,i)\in K}{e_{ui}^2}+\lambda_p ||P||<em>F^2 +\lambda_q ||Q||<em>F^2 \space]<br>$$<br>则在第 $t+1$ 次迭代中，参数 $p</em>{uj}$ 和 $q</em>{ji}$ 的更新公式为：<br>$$<br>p_{uj}^{(t+1)} \leftarrow p_{uj}^{(t)} + \epsilon(\sum_{i:(u,i)\in K}{e_{ui}^{(t)}q_{ji}^{t}}-\lambda_p p_{uj}^{(t)})<br>\<br>q_{ji}^{(t+1)} \leftarrow q_{ji}^{(t)} + \epsilon(\sum_{u:(u,i)\in K}{e_{ui}^{(t)}p_{uj}^{t}-\lambda_q q_{ji}^{(t)})}<br>$$<br>其中 $e_{ui}^{(t)}=r_{ui}-\sum_{j=1}^{K}{p_{uj}^{(t)}q_{ji}^{(t)}}$。</p><p>对一个评分系统而言，除了整体性的评分偏差外，每个用户或每个物品的评分都存在着偏差，减少偏置部分的影响能够提高预测的准确率。</p><p>考虑三种偏执信息，将偏置部分表示为：$b_{ui}=\mu + b_u + d_i$ 。其中 $\mu$ 为所有评分的平均值，$b_u$ 表示用户 $u$ 的评分偏置，$d_i$ 表示项目 $i$ 得到的评分偏置。最终得到的总的评分预测公式为：$\hat{r}_{ui} = \mu+b_u+d_i+p_u^T q_i$ 。</p><p>则矩阵分解的目标函数变为：<br>$$<br>\begin{align*}<br>&amp;\min_{P*,Q*,b*,d*}{J(R;P,Q,b,d)}<br>\<br>&amp; =\frac{1}{2}[\space \sum_{(u,i)\in K}{(r_{ui}-\hat{r}<em>{ui})^2} + \lambda_p||P||<em>F^2+\lambda_Q||Q||<em>F^2+\lambda_b||b||<em>2^2+\lambda_d||d||<em>2^2\space]<br>\<br>&amp;=\frac{1}{2}[\space \sum</em>{(u,i)\in K}{e</em>{ui}^2} + \lambda_p||P||<em>F^2+\lambda_Q||Q||<em>F^2+\lambda_b||b||<em>2^2+\lambda_d||d||<em>2^2\space]<br>\end{align*}<br>$$<br>则在第 $t+1$ 次迭代中，参数 $p</em>{uj}$、$q</em>{ji}$、$b_u$、$d_i$ 的更新公式为：<br>$$<br>\begin{align*}<br>&amp; p</em>{uj}^{(t+1)} \leftarrow p</em>{uj}^{(t)} + \epsilon(\sum</em>{i:(u,i)\in K}{e</em>{ui}^{(t)}q</em>{ji}^{(t)}}-\lambda_p p_{uj}^{(t)})<br>\<br>&amp; q_{ji}^{(t+1)} \leftarrow q_{ji}^{(t)} + \epsilon(\sum_{u:(u,i)\in K}{e_{ui}^{(t)}p_{uj}^{(t)}-\lambda_q p_{ji}^{(t)})}<br>\<br>&amp; b_u^{(t+1)} \leftarrow b_u^{(t)} + \epsilon(\sum_{i:(u,i)\in K}{e_{ui}^{(t)}-\lambda_b b_u^{(t)})}<br>\<br>&amp; d_i^{(t+1)} \leftarrow d_i^{(t)} + \epsilon(\sum_{u:(u,i)\in K}{e_{ui}^{(t)}-\lambda_d d_i^{(t)})}<br>\end{align*}<br>$$<br>其中 $e_{ui}^{(t)}=r_{ui}-\sum_{j=1}^{K}{p_{uj}^{(t)}q_{ji}^{(t)}}$ ，$\epsilon$ 为学习率或步长。</p><p>协同过滤（Collaborative Filtering）：CF是一种基于用户的协同过滤算法，它通过分析用户之间的相似度来预测用户对物品的喜好程度。</p><p>$s_{uv}$ 表示用户 $u$ 和用户 $v$ 的偏好相似度，目标是偏好相似度越高的用户在隐空间中的投影向量靠的越近。矩阵分解的目标函数变为：<br>$$<br>\begin{align*}<br>&amp;\min_{P*,Q*}{J(R;P,Q)}<br>\<br>&amp; =\frac{1}{2}[\space \sum_{(u,i)\in K}{(r_{ui}-\hat{r}<em>{ui})^2} + \gamma\sum</em>{(u,v)\in U}{s_{uv}||p_u-p_v||<em>2^2}\space]<br>\<br>&amp;=\frac{1}{2}[\space \sum</em>{(u,i)\in K}{e_{ui}^2} + \gamma\sum_{(u,v)\in U}{s_{uv}||p_u-p_v||<em>2^2}\space]<br>\end{align*}<br>$$<br>则在第 $t+1$ 次迭代中，参数 $p</em>{uj}$、$q_{ji}$ 的更新公式为：<br>$$<br>p_{uj}^{(t+1)} \leftarrow p_{uj}^{(t)} + \epsilon[\sum_{i:(u,i)\in K}{e_{ui}^{(t)}q_{ji}^{(t)}}-<br>\gamma\sum_{(u,v)\in U}{s_{uv}(p_{uj}^{(t)}-p_{vj}^{(t)})}\space]<br>\<br>q_{ji}^{(t+1)} \leftarrow q_{ji}^{(t)} + \epsilon\sum_{u:(u,i)\in K}{e_{ui}^{(t)}p_{uj}^{(t)}}<br>$$</p><h4 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h4><p>SDG_TRAIN:<br><img src="image/SGD.png"><br>BDG_TRAIN:<br><img src="./image/BDG1.png" alt=" "><br><img src="./image/BGD2.png" alt=" "><br>TEST:<br><img src="./image/%E6%B5%8B%E8%AF%95.png"><br>提交kaggle榜单，最优结果：<br><img src="./image/kaggle1.png"><br><img src="./image/kaggle.png"></p><h3 id="五-项目总结和感悟"><a href="#五-项目总结和感悟" class="headerlink" title="五.项目总结和感悟"></a>五.项目总结和感悟</h3><p>对于本次基于矩阵分解的推荐系统，实现了SGD和BGD算法，并对其进行多方面优化，更深刻的认识到了矩阵分解算法在实际生活场景的应用。<br>在矩阵分解的实现过程中，我查阅的大量资料，总结出了其几点优势与劣势，首先矩阵分解算法可以简化矩阵的表示方法，使其更容易操作和分析。另外，矩阵分解算法可以帮助提高涉及矩阵的计算的数值稳定性，特别是当矩阵很大或条件不好时。矩阵分解算法还可以深入了解矩阵的结构及其元素之间的关系，这对数据分析和机器学习任务非常有用。<br>但是对于大矩阵，矩阵分解算法可能是计算密集型的；矩阵分解算法可能不适用于所有类型的矩阵。例如，不是所有的矩阵都有唯一的分解，一些矩阵分解算法对于某些类型的矩阵可能没有很好的定义。在矩阵分解的过程中可能涉及近似和简化，这可能导致原始矩阵的一些信息损失。<br>矩阵分解算法经常被用于推荐系统中，以分析和模拟用户的偏好，并根据这些偏好进行推荐。<br>多种矩阵分解算法，如非负矩阵分解（NMF）和概率矩阵分解（PMF），都可用于推荐任务。<br>另外，除了矩阵分解算法外，其他技术，如协作过滤和基于内容的过滤，也可用于推荐任务。</p>]]></content>
    
    
    <categories>
      
      <category>算法基础</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法基础</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MyFirstBlog</title>
    <link href="/2023/05/08/MyFirstBlog/"/>
    <url>/2023/05/08/MyFirstBlog/</url>
    
    <content type="html"><![CDATA[<h1 id="Hexo写博客实验总结"><a href="#Hexo写博客实验总结" class="headerlink" title="Hexo写博客实验总结"></a>Hexo写博客实验总结</h1><h2 id="博客主题及其选取原因"><a href="#博客主题及其选取原因" class="headerlink" title="博客主题及其选取原因"></a>博客主题及其选取原因</h2><p>在实验中，我选择了Hexo官方推荐的Fluid主题作为我的博客主题。选取该主题的原因如下：</p><ul><li>该主题采用了现代化的设计语言和风格，视觉效果非常优美和清新。</li><li>该主题提供了丰富的页面和组件，如文章列表、标签云、友情链接等，使得博客的展示更加丰富和多样化。</li><li>该主题支持响应式设计和移动端优化，可以在不同设备上提供一致的用户体验。</li></ul><h2 id="博客页面布局及其设计思路"><a href="#博客页面布局及其设计思路" class="headerlink" title="博客页面布局及其设计思路"></a>博客页面布局及其设计思路</h2><p>我的博客页面布局如下：</p><ul><li>顶部导航栏：包含了博客的Logo、主页链接、归档链接、分类链接和标签链接。</li><li>主体内容区域：显示博客文章列表或者文章内容。</li><li>侧边栏：包含了标签云、分类列表、最近文章、友情链接等组件。</li></ul><p>该布局的设计思路是：将导航栏置于页面的顶部，方便用户快速访问博客的主要功能；将主体内容区域放置在页面的中心位置，突出博客的核心内容；将侧边栏放置在页面的侧边，提供一些额外的信息和功能，增加博客的互动性和可读性。</p><h2 id="博客样式设计及其美学考量"><a href="#博客样式设计及其美学考量" class="headerlink" title="博客样式设计及其美学考量"></a>博客样式设计及其美学考量</h2><p>在我的博客样式设计中，我遵循了以下美学考量：</p><ul><li>简洁：尽可能去掉不必要的装饰和干扰，突出博客的核心内容。</li><li>清晰：使用简单的排版和明确的标题，方便用户快速浏览和理解文章。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/05/08/hello-world/"/>
    <url>/2023/05/08/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
